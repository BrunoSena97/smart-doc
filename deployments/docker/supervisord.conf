; deployments/docker/supervisord.conf
[supervisord]
nodaemon=true
logfile=/var/log/smartdoc/supervisord.log
pidfile=/var/run/supervisord.pid

[program:ollama]
command=/bin/sh -c "ollama serve"
stdout_logfile=/var/log/smartdoc/ollama.out.log
stderr_logfile=/var/log/smartdoc/ollama.err.log
autorestart=true
startsecs=2
priority=10

; Warmup job: waits for Ollama, pulls models once, then exits
[program:ollama-warmup]
command=/bin/sh -c "/app/deployments/docker/warmup.sh"
stdout_logfile=/var/log/smartdoc/warmup.out.log
stderr_logfile=/var/log/smartdoc/warmup.err.log
autorestart=false
startretries=3
startsecs=3
priority=20

[program:gunicorn]
directory=/app/apps/api
command=/bin/sh -c "poetry run gunicorn -w 2 -k gthread -b 0.0.0.0:8000 'smartdoc_api:create_app()' --access-logfile - --error-logfile - --preload"
stdout_logfile=/var/log/smartdoc/gunicorn.out.log
stderr_logfile=/var/log/smartdoc/gunicorn.err.log
autorestart=true
startsecs=3
priority=30

[program:cron]
command=/usr/sbin/cron -f
stdout_logfile=/var/log/smartdoc/cron.out.log
stderr_logfile=/var/log/smartdoc/cron.err.log
autorestart=true
startsecs=0
priority=40
