services:
  ollama:
    image: ollama/ollama:0.11.7
    container_name: ollama
    environment:
      OLLAMA_HOST: "0.0.0.0"
      OLLAMA_KEEP_ALIVE: "24h"
      OLLAMA_CONTEXT_LENGTH: "4096"
    volumes:
      - smartdoc_ollama:/root/.ollama
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -fsS http://127.0.0.1:11434/api/tags >/dev/null"]
      interval: 20s
      timeout: 5s
      retries: 10
      start_period: 30s
    restart: unless-stopped

  ollama-init:
    image: ollama/ollama:0.11.7
    container_name: ollama-init
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      OLLAMA_HOST: "http://ollama:11434"
    volumes:
      - smartdoc_ollama:/root/.ollama
    # Pull all models you need here
    command: >
      bash -lc "
      ollama pull gemma3:4b-it-q4_K_M &&
      echo 'models ready' "
    restart: "no"

  smartdoc:
    build:
      context: ..
      dockerfile: deployments/Dockerfile
    container_name: smartdoc
    environment:
      FLASK_ENV: production
      LOG_LEVEL: INFO
      SMARTDOC_OLLAMA_BASE_URL: "http://ollama:11434"
      OLLAMA_MODEL: "gemma3:4b-it-q4_K_M"
      SMARTDOC_DB_URL: "sqlite:////data/smartdoc.sqlite3"
    depends_on:
      ollama:
        condition: service_healthy
      ollama-init:
        condition: service_completed_successfully
    ports:
      - "8000:8000"
    volumes:
      - smartdoc_data:/data
      - ../apps/web/public:/app/web:ro
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:8000/healthz >/dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

volumes:
  smartdoc_data:
  smartdoc_ollama:
